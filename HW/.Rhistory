## Creating a linear model relating Sales and time
model<-lm(data_sub$Sales~data_sub$Time)
summary(model)
## Plotting the model
plot(fitted(model),residuals(model))
## Predicted values
pre_variables<-predict(model,data=data_sub$Time)
## Plotting both original and predicted values
plot.ts(data_sub$Sales, lwd=2, col="Blue", xlab="Time", ylab="Data")
lines(x=data_sub$Time, y=pre_variables, col='Red', lty=2)
legend("topleft", legend=c("Original", "Predicted"),
col=c("blue", "red"), lty=1:2, cex=0.8)
data_sub$Predicted<-pre_variables
data_sub$Resdiuals<-as.numeric(data_sub$Sales)-as.numeric(data_sub$Predicted)
## Reading the data
library("xlsx")
data<-read.xlsx("Retail_Sales_Data.xlsx",sheetIndex = 1, header=FALSE, stringsAsFactors=FALSE)
## Changing the column names for our convinience
colnames(data)<-c("Year","Month","Sales")
## Removing first 2 lines
data_sub<-data[3:length(data$Year), ]
## Converting the date and month to numbers
data_sub$Time<-c(1:length(data_sub$Sales))
## Creating a linear model relating Sales and time
model<-lm(data_sub$Sales~data_sub$Time)
summary(model)
## Plotting the model
plot(fitted(model),residuals(model))
## Predicted values
pre_variables<-predict(model,data=data_sub$Time)
## Plotting both original and predicted values
plot.ts(data_sub$Sales, lwd=2, col="Blue", xlab="Time", ylab="Data")
lines(x=data_sub$Time, lwd=2, y=pre_variables, col='Red', lty=2)
legend("topleft", legend=c("Original", "Predicted"),
col=c("blue", "red"), lty=1:2, cex=0.8)
data_sub$Predicted<-pre_variables
data_sub$Resdiuals<-as.numeric(data_sub$Sales)-as.numeric(data_sub$Predicted)
data_sub$Predicted<-pre_variables
data_sub$Resdiuals<-as.numeric(data_sub$Sales)-as.numeric(data_sub$Predicted)
# AR(2)
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = 2)
res
#data_sub$Resdiuals_pre<-predict(res,data_sub$Resdiuals)
#plot.ts(data_sub$Resdiuals)
#lines(x=data_sub$Time,y=data_sub$Resdiuals_pre)
length(data_sub$Time)
res$order
res$ar
res$var.pred
data_sub$Predicted<-pre_variables
data_sub$Resdiuals<-as.numeric(data_sub$Sales)-as.numeric(data_sub$Predicted)
# AR(2)
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = 2)
res
# Residual Sum of squares
print(paste("The value of residual sum of squares is",prettyNum((length(data_sub$Year)-1)*res$var.pred)))
#data_sub$Resdiuals_pre<-predict(res,data_sub$Resdiuals)
#plot.ts(data_sub$Resdiuals)
#lines(x=data_sub$Time,y=data_sub$Resdiuals_pre)
# AR(4)
res_4<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = 4)
res_4
# Residual Sum of squares
print(paste("The value of residual sum of squares is",prettyNum((length(data_sub$Year)-1)*res_4$var.pred)))
2:20:2
seq(2,20)
seq(2,20,2)
res_sum_sq=rep(0L,10)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
rep_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
View(res_4)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
plot(x=data_sub$Time, y=res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
plot(x=1:length(res_sum_sq), y=res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
plot(x=seq(2,20,2), y=res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
plot(x=seq(2,20,2), y=res_sum_sq, pch=16)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
library(ggplot2)
ggplot(x=seq(2,20,2), y=res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
library(ggplot2)
ggplot(aes(x=seq(2,20,2), y=res_sum_sq))
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum_sq$model_num=seq(2,20,2)
library(ggplot2)
ggplot(aes(x=seq(2,20,2), y=res_sum_sq))
res_sum_sq<-data_frame(res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum_sq<-data_frame(res_sum_sq)
res_sum_sq$model_num=seq(2,20,2)
# library(ggplot2)
# ggplot(aes(x=seq(2,20,2), y=res_sum_sq))
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum_sq<-data_frame(res_sum_sq)
res_sum_sq$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum_sq,aes(x=res_sum_sq$model_num, y=res_sum_sq$res_sum_sq))+geom_line()
View(res_sum_sq)
View(res_sum_sq)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_line()
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))++geom_point()+geom_line()
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))++geom_point(aes(color = 'Red'))+geom_line(aes(color = 'green'))
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_point(aes(color = 'Red'))+geom_line(aes(color = 'green'))
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_point(aes(color = 'Red'))+geom_line(aes(color = 'green'))+xlab("Order")+ylab("Residual sum of squares")
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_point(aes(color = 'Red'),show.legend = FALSE)+geom_line(aes(color = 'green'),show.legend = FALSE)+xlab("Order")+ylab("Residual sum of squares")
# Setosa
setosa_ratio <- filter(iris_ratio, Species=='setosa')
cor.test(setosa_ratio$Sepal.Length, setosa_ratio$ratio)
# Versicolor
versicolor_ratio <- filter(iris_ratio, Species=='versicolor')
cor.test(versicolor_ratio$Sepal.Length, versicolor_ratio$ratio)
# Virginica
virginica_ratio <- filter(iris_ratio, Species=='virginica')
cor.test(virginica_ratio$Sepal.Length, virginica_ratio$ratio)
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data_frame(res_sum_sq)
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_point(aes(color = 'Red'),show.legend = FALSE)+geom_line(aes(color = 'green'),show.legend = FALSE)+xlab("Order")+ylab("Residual sum of squares")
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data.frame()
res_sum$res_sum_sq<-res_sum_sq
res_sum_sq=rep(0L,10)
for (i in seq(2,20,2)){
res<-ar.ols(x = data_sub$Resdiuals, aic = FALSE, order.max = i)
res_sum_sq[i/2]=res$var.pred*(length(data_sub$Year)-1)
}
res_sum<-data.frame(res_sum_sq)
#res_sum$res_sum_sq<-res_sum_sq
res_sum$model_num=seq(2,20,2)
library(ggplot2)
ggplot(res_sum,aes(x=res_sum$model_num, y=res_sum$res_sum_sq))+geom_point(aes(color = 'Red'),show.legend = FALSE)+geom_line(aes(color = 'green'),show.legend = FALSE)+xlab("Order")+ylab("Residual sum of squares")
library(knitr)
opts_chunk$set(fig.align = "center", fig.height = 5, fig.width = 6)
library(tidyverse)
theme_set(theme_bw(base_size = 12))
library(ggthemes)
flavors_of_cacao <-
read_csv("https://raw.githubusercontent.com/clauswilke/dviz.supp/master/data-raw/cacao/cacao_clean.csv") %>%
extract(cocoa_percent, "cocoa_percent", regex = "([^%]+)%", convert = TRUE)
head(flavors_of_cacao)
# We want to find number of reviews for each location
flavors_of_cacao %>%
group_by(location) %>% # First we are grouping the data based on location like "USA","Italy"
summarize(number_reviews = n(), min_rate = min(rating), max_rate = max(rating))->
#summarize counts the number of reviews for each location and calculates a minimum and a maximum ratings of each location
flavors_of_cacao_location
# To see the outcome of the above
flavors_of_cacao_location
# Since we want only those places with total number of reviews greater than 20, we filter the rows and arrange in descending order
flavors_of_cacao_location  %>%
filter((number_reviews) > 20) %>%
arrange(desc(number_reviews))-> flavors_of_cacao_new
# To see the resultant data after we filtered accordingly
flavors_of_cacao_new
# Finding the location with highest maximum rating
flavors_of_cacao_new  %>%
filter(max_rate==max(flavors_of_cacao_new$max_rate))
# Finding the location with lowest minimum rating
flavors_of_cacao_new  %>%
filter(min_rate==min(flavors_of_cacao_new$min_rate))
flavors_of_cacao %>%
filter(location == 'Italy') -> italy
flavors_of_cacao %>%
filter(location == 'Belgium') -> belgium
t.test(italy$rating,belgium$rating)
# Finding the location with highest maximum rating
flavors_of_cacao_new  %>%
filter(max_rate==max(flavors_of_cacao_new$max_rate))
# Finding the location with lowest minimum rating
flavors_of_cacao_new  %>%
filter(min_rate==min(flavors_of_cacao_new$min_rate))
# To do the statistical we need to get data of each location into two different variables
# Knowing that Italy has the highest max rating, we filter data with location Italy
flavors_of_cacao %>%
filter(location == 'Italy') -> italy
# Knowing that Belgium has the lowest min rating, we filter data with location Belgium
flavors_of_cacao %>%
filter(location == 'Belgium') -> belgium
# Doing t-test between the ratings of the two locations
t.test(italy$rating,belgium$rating)
ggplot(flavors_of_cacao_tidy, aes(x=number_reviews, y=ratings, color=min_max))+geom_point()+geom_smooth()
library(knitr)
opts_chunk$set(fig.align = "center", fig.height = 5, fig.width = 6)
library(tidyverse)
theme_set(theme_bw(base_size = 12))
library(ggthemes)
flavors_of_cacao <-
read_csv("https://raw.githubusercontent.com/clauswilke/dviz.supp/master/data-raw/cacao/cacao_clean.csv") %>%
extract(cocoa_percent, "cocoa_percent", regex = "([^%]+)%", convert = TRUE)
head(flavors_of_cacao)
# We want to find number of reviews for each location
flavors_of_cacao %>%
group_by(location) %>% # First we are grouping the data based on location like "USA","Italy"
summarize(number_reviews = n(), min_rate = min(rating), max_rate = max(rating))->
#summarize counts the number of reviews for each location and calculates a minimum and a maximum ratings of each location
flavors_of_cacao_location
# To see the outcome of the above
flavors_of_cacao_location
# Since we want only those places with total number of reviews greater than 20, we filter the rows and arrange in descending order
flavors_of_cacao_location  %>%
filter((number_reviews) > 20) %>%
arrange(desc(number_reviews))-> flavors_of_cacao_new
# To see the resultant data after we filtered accordingly
flavors_of_cacao_new
# Finding the location with highest maximum rating
flavors_of_cacao_new  %>%
filter(max_rate==max(flavors_of_cacao_new$max_rate))
# Finding the location with lowest minimum rating
flavors_of_cacao_new  %>%
filter(min_rate==min(flavors_of_cacao_new$min_rate))
# To do the statistical we need to get data of each location into two different variables
# Knowing that Italy has the highest max rating, we filter data with location Italy
flavors_of_cacao %>%
filter(location == 'Italy') -> italy
# Knowing that Belgium has the lowest min rating, we filter data with location Belgium
flavors_of_cacao %>%
filter(location == 'Belgium') -> belgium
# Doing t-test between the ratings of the two locations
t.test(italy$rating,belgium$rating)
library(knitr)
opts_chunk$set(fig.align = "center", fig.height = 5, fig.width = 6)
library(tidyverse)
theme_set(theme_bw(base_size = 12))
library(ggthemes)
flavors_of_cacao <-
read_csv("https://raw.githubusercontent.com/clauswilke/dviz.supp/master/data-raw/cacao/cacao_clean.csv") %>%
extract(cocoa_percent, "cocoa_percent", regex = "([^%]+)%", convert = TRUE)
head(flavors_of_cacao)
# We want to find number of reviews for each location
flavors_of_cacao %>%
group_by(location) %>% # First we are grouping the data based on location like "USA","Italy"
summarize(number_reviews = n(), min_rate = min(rating), max_rate = max(rating))->
#summarize counts the number of reviews for each location and calculates a minimum and a maximum ratings of each location
flavors_of_cacao_location
# To see the outcome of the above
flavors_of_cacao_location
# Since we want only those places with total number of reviews greater than 20, we filter the rows and arrange in descending order
flavors_of_cacao_location  %>%
filter((number_reviews) > 20) %>%
arrange(desc(number_reviews))-> flavors_of_cacao_new
# To see the resultant data after we filtered accordingly
flavors_of_cacao_new
# Finding the location with highest maximum rating
flavors_of_cacao_new  %>%
filter(max_rate==max(flavors_of_cacao_new$max_rate))
# Finding the location with lowest minimum rating
flavors_of_cacao_new  %>%
filter(min_rate==min(flavors_of_cacao_new$min_rate))
# To do the statistical we need to get data of each location into two different variables
# Knowing that Italy has the highest max rating, we filter data with location Italy
flavors_of_cacao %>%
filter(location == 'Italy') -> italy
# Knowing that Belgium has the lowest min rating, we filter data with location Belgium
flavors_of_cacao %>%
filter(location == 'Belgium') -> belgium
# Doing t-test between the ratings of the two locations
t.test(italy$rating,belgium$rating)
# Prints out the Untidy dataset
flavors_of_cacao_new
# Since there are two columns min rate and max rate which is acutually a variable so there should
# be one column saying whether it is max or min. There should be another column with the value of ratings.
# convert to tidy dataset using gather
flavors_of_cacao_new %>%
gather(min_max,ratings,min_rate:max_rate)-> flavors_of_cacao_tidy
# Prints out the tidy dataset
flavors_of_cacao_tidy
ggplot(flavors_of_cacao_tidy, aes(x=number_reviews, y=ratings, color=min_max))+geom_point()+geom_smooth()
# Prints out the Untidy dataset
flavors_of_cacao_new
# Since there are two columns min rate and max rate which is acutually a variable so there should
# be one column saying whether it is max or min. There should be another column with the value of ratings.
# convert to tidy dataset using gather
flavors_of_cacao_new %>%
gather(min_max,ratings,min_rate:max_rate)-> flavors_of_cacao_tidy
# Prints out the tidy dataset
flavors_of_cacao_tidy
ggplot(flavors_of_cacao_tidy, aes(x=number_reviews, y=ratings, color=min_max))+geom_point()#+geom_smooth()
#(unique(flavors_of_cacao$company))
summary(fit)
library(knitr)
opts_chunk$set(fig.align = "center", fig.height = 5, fig.width = 6)
library(tidyverse)
theme_set(theme_bw(base_size = 12))
library(ggthemes)
flavors_of_cacao <-
read_csv("https://raw.githubusercontent.com/clauswilke/dviz.supp/master/data-raw/cacao/cacao_clean.csv") %>%
extract(cocoa_percent, "cocoa_percent", regex = "([^%]+)%", convert = TRUE)
head(flavors_of_cacao)
# We want to find number of reviews for each location
flavors_of_cacao %>%
group_by(location) %>% # First we are grouping the data based on location like "USA","Italy"
summarize(number_reviews = n(), min_rate = min(rating), max_rate = max(rating))->
#summarize counts the number of reviews for each location and calculates a minimum and a maximum ratings of each location
flavors_of_cacao_location
# To see the outcome of the above
flavors_of_cacao_location
# Since we want only those places with total number of reviews greater than 20, we filter the rows and arrange in descending order
flavors_of_cacao_location  %>%
filter((number_reviews) > 20) %>%
arrange(desc(number_reviews))-> flavors_of_cacao_new
# To see the resultant data after we filtered accordingly
flavors_of_cacao_new
# Finding the location with highest maximum rating
flavors_of_cacao_new  %>%
filter(max_rate==max(flavors_of_cacao_new$max_rate))
# Finding the location with lowest minimum rating
flavors_of_cacao_new  %>%
filter(min_rate==min(flavors_of_cacao_new$min_rate))
# To do the statistical we need to get data of each location into two different variables
# Knowing that Italy has the highest max rating, we filter data with location Italy
flavors_of_cacao %>%
filter(location == 'Italy') -> italy
# Knowing that Belgium has the lowest min rating, we filter data with location Belgium
flavors_of_cacao %>%
filter(location == 'Belgium') -> belgium
# Doing t-test between the ratings of the two locations
t.test(italy$rating,belgium$rating)
# Prints out the Untidy dataset
flavors_of_cacao_new
# Since there are two columns min rate and max rate which is acutually a variable so there should
# be one column saying whether it is max or min. There should be another column with the value of ratings.
# convert to tidy dataset using gather
flavors_of_cacao_new %>%
gather(min_max,ratings,min_rate:max_rate)-> flavors_of_cacao_tidy
# Prints out the tidy dataset
flavors_of_cacao_tidy
ggplot(flavors_of_cacao_tidy, aes(x=number_reviews, y=ratings, color=min_max))+geom_point()#+geom_smooth()
head(flavors_of_cacao)
flavors_of_cacao
ggplot(flavors_of_cacao, aes(x=cocoa_percent, y=rating))+geom_point()+geom_smooth()
(unique(flavors_of_cacao$cocoa_percent))
ggplot(flavors_of_cacao, aes(x=bean_origin, y=rating))+geom_point()+geom_smooth()
(unique(flavors_of_cacao$bean_origin))
ggplot(flavors_of_cacao, aes(x=bean_type, y=rating))+geom_point()+geom_smooth()
(unique(flavors_of_cacao$bean_type))
#(unique(flavors_of_cacao$bean_origin_detailed))
flavors.mod <- lm(rating ~ location, data = flavors_of_cacao)
anova(flavors.mod)
fit<-lm(rating~cocoa_percent, data=flavors_of_cacao)
anova(fit)
#(unique(flavors_of_cacao$company))
summary(fit)
fit<-lm(rating~cocoa_percent+company+location, data=flavors_of_cacao)
anova(fit)
#(unique(flavors_of_cacao$company))
summary(fit)
knitr::opts_chunk$set(echo = TRUE)
## To read the data file
library("xlsx")
data<-read.xlsx("HW1_Problem1.xls",sheetIndex = 1, header=FALSE, stringsAsFactors=FALSE)
## Hardcoding to find those parameters
sum=0
sum_sq=0
mu=mean(data$X1)
var_data=0
## Before going forward to do the model fitting, we need to subtract the data by its mean
data$X1<-data$X1-mu
## Calculating Phi_1
for (i in 1:49) {
sum = sum + ((data$X1[i])*(data$X1[i+1]))
sum_sq = sum_sq+((data$X1[i]))^2 #*(data$X1[i]))
}
phi_1=sum/sum_sq
print(paste("The value of phi_1 is",prettyNum(phi_1)))
## Calculating variance of white noise and phi_1
for (i in 1:49) {
var_data=var_data+(data$X1[i+1]-phi_1*data$X1[i])^2
}
var_data=var_data/49
var_phi=var_data/sum_sq
print(paste("The value of variance of white noise is",prettyNum(var_data),"and that of phi_1 is",prettyNum(var_phi)))
## In built function to fit data in AR model with order 1
model<-ar.mle(x = data$X1, aic = FALSE, order.max = 1)
## Prints out co-efficient and variance value of white noise
model
data$time<-1:length(data$X1)
data$predict<-rep(0,length(data$X1))
#data_predicted<-data_frame()
#data$predict<-predict(model, data$X1)
#data$predict<-predict(model, data$X1, n.ahead = 1, se.fit = TRUE)
for (i in 1:49) {
data$predict[i+1]=data$X1[i]*phi_1
}
plot.ts(data$X1, lwd=2, col="Blue", xlab="Time", ylab="Data")
lines(x=data$time, y=data$predict, col='Red', lty=2 )
legend("topright", legend=c("Original", "Predicted"),
col=c("blue", "red"), lty=1:2, cex=0.8)
## Reading the data
library("xlsx")
data<-read.xlsx("Retail_Sales_Data.xlsx",sheetIndex = 1, header=FALSE, stringsAsFactors=FALSE)
## Changing the column names for our convinience
colnames(data)<-c("Year","Month","Sales")
## Removing first 2 lines
data_sub<-data[3:length(data$Year), ]
## Converting the date and month to numbers
data_sub$Time<-c(1:length(data_sub$Sales))
## Creating a linear model relating Sales and time
model<-lm(data_sub$Sales~data_sub$Time)
summary(model)
## Plotting the model
plot(fitted(model),residuals(model))
## Predicted values
pre_variables<-predict(model,data=data_sub$Time)
## Plotting both original and predicted values
plot.ts(data_sub$Sales, lwd=2, col="Blue", xlab="Time", ylab="Sales")
lines(x=data_sub$Time, lwd=2, y=pre_variables, col='Red', lty=2)
legend("topleft", legend=c("Original", "Predicted"),
col=c("blue", "red"), lty=1:2, cex=0.8)
